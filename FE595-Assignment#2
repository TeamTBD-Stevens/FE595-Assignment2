def project2(URL, iterations):

    import requests as req

    data = []

    for _ in range(iterations):

        resp = req.get(URL)

        if resp.status_code != 200:
            return False

        s = resp.text.split("<li>")

        name = [i for i in s if 'Name: ' in i]
        purpose = [i for i in s if 'Purpose: ' in i]

        name = name[0]
        name2 = name[name.find('Name: ')+len('Name: '):name.rfind('CEO: ')]
        name3 = name2.replace("<li>", "")
        split_string = name3.split("</li>", 1)
        name4 = split_string[0]

        purpose = purpose[0]
        purpose2 = purpose[purpose.find('Purpose: ')+len('Purpose: '):purpose.rfind('Investment')]
        purpose3 = purpose2.replace("<li>", "")
        split_string = purpose3.split("</li>", 1)
        purpose4 = split_string[0]

        data.append(name4)
        data.append(purpose4)

    print(data)
    with open("webscraping.txt", "w") as output:
        output.write(str(data))

if __name__ == "__main__":
    project2("http://3.95.249.159:8000/random_company", 50)
